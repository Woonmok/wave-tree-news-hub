#!/usr/bin/env python3
# news_hub.py (í‚¤ì›Œë“œ í•„í„°ë§ ê¸°ëŠ¥ í¬í•¨)
import requests
from google.generativeai import GenerativeModel
from datetime import datetime
import json
import os

# ===== ì„¤ì • =====
KEYWORDS = [
    "ê· ì‚¬ì²´", "mycelium", "ë°°ì–‘ìœ¡", "cultured meat",
    "ì§„ì•ˆ", "POM", "Bio-R&D", "ë°”ì´ì˜¤",
    "cell-based", "fermentation", "ë°°ì–‘",
    "listeria", "ë¦¬ìŠ¤í…Œë¦¬ì•„", "ê³ ê¸‰ ì˜¤ë””ì˜¤", "í•˜ì´ì—”ë“œ",
    "ai", "computer", "gpu", "blackwell"
]

EXCLUDE_KEYWORDS = [
    "ê´‘ê³ ", "ìŠ¤í°ì„œ", "sponsored", "promo", "affiliate"
]

# 1. í‚¤ì›Œë“œ í•„í„°ë§ í•¨ìˆ˜
def filter_by_keywords(news_text, keywords=KEYWORDS, exclude=EXCLUDE_KEYWORDS):
    """íŠ¹ì • í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë‰´ìŠ¤ë§Œ ì„ íƒ"""
    text_lower = news_text.lower()
    
    # ì œì™¸ í‚¤ì›Œë“œ í™•ì¸
    for exclude_kw in exclude:
        if exclude_kw.lower() in text_lower:
            return False, "ì œì™¸ í‚¤ì›Œë“œ í¬í•¨"
    
    # í¬í•¨ í‚¤ì›Œë“œ í™•ì¸
    matched_keywords = [kw for kw in keywords if kw.lower() in text_lower]
    if matched_keywords:
        return True, matched_keywords
    
    return False, "ê´€ë ¨ í‚¤ì›Œë“œ ì—†ìŒ"


# 2. ì •ë³´ ìˆ˜ì§‘ (RSS/API)
def fetch_news():
    """ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ (ìƒ˜í”Œ ë˜ëŠ” ì‹¤ì œ API)"""
    # ì‹¤ì œë¡œëŠ” ë‰´ìŠ¤ APIë‚˜ RSS í”¼ë“œë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
    sample_news = [
        "ë¯¸êµ­ ì‹œì¥ ë‚´ ê· ì‚¬ì²´(Mycelium) ê¸°ë°˜ ë°°ì–‘ìœ¡ ì ìœ ìœ¨ ê¸‰ì¦...",
        "ìŠ¤íƒ€íŠ¸ì—… ê´‘ê³ : ìƒˆ ì œí’ˆ ì¶œì‹œ ìŠ¤í°ì„œë¨",
        "ì§„ì•ˆ POM í”„ë¡œì íŠ¸, ì„¸í¬ ë°°ì–‘ ê¸°ìˆ  íŠ¹í—ˆ íšë“",
        "ì¼ë°˜ ì†Œì‹: ë‚ ì”¨ê°€ ì¢‹ìŠµë‹ˆë‹¤",
        "FDA ë¦¬ìŠ¤í…Œë¦¬ì•„ ê¸´ê¸‰ ì•Œë¦¼ ë°œí‘œ",
        "ê³ ê¸‰ ì˜¤ë””ì˜¤ ê¸°ìˆ  ìµœì‹  ë™í–¥",
        "GPU ê¸°ìˆ  í˜ì‹ , AI ì„±ëŠ¥ í–¥ìƒ",
    ]
    return sample_news


# 3. Geminië¥¼ í†µí•œ ì „ëµì  í•„í„°ë§ (ëˆˆì˜ ì—­í• )
def analyze_importance(news_text, matched_keywords):
    """Geminië¥¼ ì‚¬ìš©í•œ ë‰´ìŠ¤ ì¤‘ìš”ë„ ë¶„ì„ (ì„ íƒì‚¬í•­)"""
    try:
        model = GenerativeModel('gemini-pro')
        keywords_str = ", ".join(matched_keywords)
        prompt = f"""ë‹¤ìŒ ë‰´ìŠ¤ê°€ í”„ë¡œì íŠ¸ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ë ¥ì„ 1-10ì ìœ¼ë¡œ í‰ê°€í•˜ê³  ìš”ì•½í•´ì¤˜.
    
ê°ì§€ëœ í‚¤ì›Œë“œ: {keywords_str}

ë‰´ìŠ¤: {news_text}

í˜•ì‹: [ì ìˆ˜/10] | [ì œëª©(í•œì¤„)] | [ë¶„ì„(2-3ì¤„)]"""
        
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        # API ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ë¶„ì„
        return f"[ë¶„ì„ ë¶ˆê°€] {', '.join(matched_keywords)} í¬í•¨ ë‰´ìŠ¤"


# 4. ê²°ê³¼ ì €ì¥ (Markdown)
def save_to_radar(news_text, matched_keywords, analysis=None):
    """Project_Radar.mdì— ê²°ê³¼ ì €ì¥"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    radar_file = "Project_Radar.md"
    
    # íŒŒì¼ì´ ì—†ìœ¼ë©´ í—¤ë” ìƒì„±
    if not os.path.exists(radar_file):
        with open(radar_file, "w", encoding="utf-8") as f:
            f.write("# Project Radar - ë‰´ìŠ¤ ê°ì§€ ë¡œê·¸\n\n")
    
    with open(radar_file, "a", encoding="utf-8") as f:
        f.write(f"## [{timestamp}] ì‹ ê·œ ê°ì§€\n")
        f.write(f"**ë‰´ìŠ¤**: {news_text[:100]}...\n\n")
        f.write(f"**ê°ì§€ í‚¤ì›Œë“œ**: {', '.join(matched_keywords)}\n\n")
        if analysis:
            f.write(f"**ë¶„ì„**: {analysis}\n")
        f.write("\n---\n\n")


# 5. JSONìœ¼ë¡œë„ ì €ì¥ (API ì—°ë™ ìš©)
def save_to_json(news_data):
    """ê°ì§€ëœ ë‰´ìŠ¤ë¥¼ JSONìœ¼ë¡œ ì €ì¥"""
    json_file = "detected_news.json"
    
    try:
        with open(json_file, "r", encoding="utf-8") as f:
            data = json.load(f)
    except FileNotFoundError:
        data = []
    
    data.append({
        "timestamp": datetime.now().isoformat(),
        "news": news_data["text"],
        "keywords": news_data["keywords"],
        "analysis": news_data.get("analysis", "")
    })
    
    with open(json_file, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


# 6. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def process_news(use_gemini=False):
    """ë‰´ìŠ¤ í•„í„°ë§ ë° ë¶„ì„ ë©”ì¸ í•¨ìˆ˜"""
    news_list = fetch_news()
    processed_count = 0
    skipped_count = 0
    
    print("=" * 60)
    print("ğŸ” ë‰´ìŠ¤ í•„í„°ë§ ë° ë¶„ì„ ì‹œì‘")
    print("=" * 60)
    print(f"ğŸ“‹ ê°ì§€ í‚¤ì›Œë“œ ({len(KEYWORDS)}ê°œ): {', '.join(KEYWORDS[:5])}...")
    print(f"ğŸš« ì œì™¸ í‚¤ì›Œë“œ ({len(EXCLUDE_KEYWORDS)}ê°œ): {', '.join(EXCLUDE_KEYWORDS)}\n")
    
    for idx, news in enumerate(news_list, 1):
        print(f"\n[{idx}/{len(news_list)}] ì²˜ë¦¬ ì¤‘...")
        print(f"   ğŸ“ ë‰´ìŠ¤: {news[:60]}...")
        
        # í‚¤ì›Œë“œ í•„í„°ë§
        is_relevant, result = filter_by_keywords(news)
        
        if not is_relevant:
            print(f"   âœ— ê±´ë„ˆëœ€: {result}")
            skipped_count += 1
            continue
        
        matched_keywords = result
        print(f"   âœ“ í•„í„° í†µê³¼!")
        print(f"   ğŸ¯ ê°ì§€ëœ í‚¤ì›Œë“œ: {', '.join(matched_keywords)}")
        
        # Gemini ë¶„ì„ (ì„ íƒì‚¬í•­)
        analysis = None
        if use_gemini:
            try:
                analysis = analyze_importance(news, matched_keywords)
                print(f"   ğŸ“Š ë¶„ì„ ì™„ë£Œ")
            except Exception as e:
                print(f"   âš ï¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        
        # Markdown ì €ì¥
        try:
            save_to_radar(news, matched_keywords, analysis)
            print(f"   ğŸ’¾ Markdown ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            print(f"   âš ï¸ ì €ì¥ ì˜¤ë¥˜: {str(e)}")
        
        # JSON ì €ì¥
        try:
            save_to_json({
                "text": news,
                "keywords": matched_keywords,
                "analysis": analysis or ""
            })
            print(f"   ğŸ’¾ JSON ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            print(f"   âš ï¸ JSON ì €ì¥ ì˜¤ë¥˜: {str(e)}")
        
        processed_count += 1
    
    print("\n" + "=" * 60)
    print(f"âœ… ì²˜ë¦¬ ì™„ë£Œ")
    print(f"   âœ“ ì €ì¥ë¨: {processed_count}ê°œ")
    print(f"   âœ— ê±´ë„ˆëœ€: {skipped_count}ê°œ")
    print(f"   ğŸ“ ìƒì„± íŒŒì¼: Project_Radar.md, detected_news.json")
    print("=" * 60)


# ì‹¤í–‰
if __name__ == "__main__":
    # use_gemini=Trueë¡œ ì„¤ì •í•˜ë©´ Gemini API ì‚¬ìš© (API í‚¤ í•„ìš”)
    process_news(use_gemini=False)

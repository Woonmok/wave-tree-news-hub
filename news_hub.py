#!/usr/bin/env python3
# news_hub.py (Gemini API ê¸°ë°˜ ë‰´ìŠ¤ ë¶„ì„ + Daily Bridge)
import os
import re
import time
from dotenv import load_dotenv
from google import genai
from datetime import datetime
import json
import shutil
import requests

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# Gemini API ì„¤ì •
API_KEY = os.getenv("GOOGLE_API_KEY", "").strip()
if not API_KEY or API_KEY == "YOUR_GEMINI_API_KEY":
    raise RuntimeError("GOOGLE_API_KEY is missing or invalid in .env")

MODEL_NAME = "gemini-2.5-flash"
client = genai.Client(api_key=API_KEY)

# ê²½ë¡œ ì„¤ì •
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
WORK_DIR = BASE_DIR
DAILY_BRIDGE_PATH = os.path.join(BASE_DIR, "Daily_Bridge.md")

ANTIGRAVITY_PATH = os.getenv("ANTIGRAVITY_PATH", "").strip()
if not ANTIGRAVITY_PATH:
    workspace_root = os.path.abspath(os.path.join(BASE_DIR, ".."))
    ANTIGRAVITY_PATH = os.path.join(workspace_root, "woonmok.github.io", "Project_Radar.md")

# ===== ì„¤ì • =====
KEYWORDS = [
    "ê· ì‚¬ì²´", "mycelium", "ë°°ì–‘ìœ¡", "cultured meat",
    "ì§„ì•ˆ", "POM", "Bio-R&D", "ë°”ì´ì˜¤",
    "cell-based", "fermentation", "ë°°ì–‘",
    "listeria", "ë¦¬ìŠ¤í…Œë¦¬ì•„", "ê³ ê¸‰ ì˜¤ë””ì˜¤", "í•˜ì´ì—”ë“œ",
    "ai", "computer", "gpu", "blackwell"
]

EXCLUDE_KEYWORDS = [
    "ê´‘ê³ ", "ìŠ¤í°ì„œ", "sponsored", "promo", "affiliate"
]


def generate_text(prompt):
    response = client.models.generate_content(
        model=MODEL_NAME,
        contents=prompt,
    )
    return response.text or ""


def generate_text_with_retry(prompt, max_retries=3, base_delay=20):
    last_error = None
    for attempt in range(1, max_retries + 1):
        try:
            return generate_text(prompt)
        except Exception as e:
            last_error = e
            err_text = str(e)
            if "RESOURCE_EXHAUSTED" in err_text or "429" in err_text:
                delay = base_delay * attempt
                print(f"   â³ ì¿¼í„° ëŒ€ê¸° {delay}s í›„ ìž¬ì‹œë„ ({attempt}/{max_retries})")
                time.sleep(delay)
                continue
            raise
    raise last_error

# 1. í‚¤ì›Œë“œ í•„í„°ë§ í•¨ìˆ˜
def filter_by_keywords(news_text, keywords=KEYWORDS, exclude=EXCLUDE_KEYWORDS):
    """íŠ¹ì • í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë‰´ìŠ¤ë§Œ ì„ íƒ"""
    text_lower = news_text.lower()
    
    # ì œì™¸ í‚¤ì›Œë“œ í™•ì¸
    for exclude_kw in exclude:
        if exclude_kw.lower() in text_lower:
            return False, "ì œì™¸ í‚¤ì›Œë“œ í¬í•¨"
    
    # í¬í•¨ í‚¤ì›Œë“œ í™•ì¸
    matched_keywords = [kw for kw in keywords if kw.lower() in text_lower]
    if matched_keywords:
        return True, matched_keywords
    
    return False, "ê´€ë ¨ í‚¤ì›Œë“œ ì—†ìŒ"


# 2. ì •ë³´ ìˆ˜ì§‘ (RSS/API)
def fetch_news():
    """ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ (2026ë…„ ì‹œìž¥ íŠ¸ë Œë“œ ì‹œë®¬ë ˆì´ì…˜)"""
    # ì‹¤ì œ ìš´ì˜ ì‹œ: NewsAPIë‚˜ RSS í”¼ë“œë¥¼ ì—°ë™í•©ë‹ˆë‹¤.
    sample_news = [
        "ë¯¸êµ­ ë‚´ ë°°ì–‘ìœ¡ ì‹œìž¥, ê³ ë¹„ìš© ë¬¸ì œë¡œ ì„¸í¬ ë°°ì–‘ ë°©ì‹ì—ì„œ ê· ì‚¬ì²´(Mycelium) ê¸°ë°˜ ë°œíš¨ ë°©ì‹ìœ¼ë¡œ ê¸‰ê²©í•œ ì´ë™ ì¤‘",
        "Better Meat Co ë° Prime Roots, ì‚°ì—…ìš© ì—°ì† ë°œíš¨ ì‹œìŠ¤í…œ ë„ìž…ìœ¼ë¡œ ìƒì‚° ë‹¨ê°€ 30% ì ˆê° ì„±ê³µ",
        "2026ë…„ í‘¸ë“œí…Œí¬ íŠ¸ë Œë“œ: 'Precision Fermentation'ê³¼ ë²„ì„¯ ê· ì‚¬ì²´ë¥¼ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ë‹¨ë°±ì§ˆ ë¶€ìƒ",
        "FDA ë¦¬ìŠ¤í…Œë¦¬ì•„ ê¸´ê¸‰ ì•Œë¦¼ ë°œí‘œ - ëƒ‰ìž¥ ì‹í’ˆ ê´€ë ¨",
        "ê³ ê¸‰ ì˜¤ë””ì˜¤ ê¸°ìˆ  ìµœì‹  ë™í–¥ - DSD í¬ë§· ì£¼ë¥˜í™”",
        "NVIDIA Blackwell GPU, AI ì¸í”„ë¼ í˜ì‹  ì£¼ë„",
        "ìŠ¤íƒ€íŠ¸ì—… ê´‘ê³ : ìƒˆ ì œí’ˆ ì¶œì‹œ ìŠ¤í°ì„œë¨ (ì œì™¸ ëŒ€ìƒ)",
    ]
    return sample_news


# 3. Geminië¥¼ í†µí•œ ì „ëžµì  í•„í„°ë§ (ëˆˆì˜ ì—­í• )
def analyze_importance(news_text, matched_keywords):
    """Geminië¥¼ ì‚¬ìš©í•œ ë‰´ìŠ¤ ì¤‘ìš”ë„ ë¶„ì„"""
    try:
        keywords_str = ", ".join(matched_keywords)
        prompt = f"""ë‹¹ì‹ ì€ 'ì§„ì•ˆ Farmerstree' í”„ë¡œì íŠ¸ì˜ ì „ëžµ AIìž…ë‹ˆë‹¤.
ë‹¤ìŒ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”:
1. í”„ë¡œì íŠ¸(ê· ì‚¬ì²´ ë°°ì–‘ìœ¡, ê³ ê¸‰ ì˜¤ë””ì˜¤, AI ì¸í”„ë¼)ì™€ì˜ ê´€ë ¨ì„± ì ìˆ˜ (1-10)
2. ì „ëžµì  í‰ê°€ (2-3ì¤„)
3. ì•¡ì…˜ ì•„ì´í…œ (ìžˆìœ¼ë©´)

ê°ì§€ëœ í‚¤ì›Œë“œ: {keywords_str}

ë‰´ìŠ¤: {news_text}

í˜•ì‹:
[ì ìˆ˜/10] | [ì œëª© í•œì¤„] 
ë¶„ì„: [ë‚´ìš©]
ì•¡ì…˜: [í•„ìš”ì‹œ]"""
        
        response_text = generate_text_with_retry(prompt)
        return response_text if response_text else f"[ë¶„ì„ ë¶ˆê°€] {', '.join(matched_keywords)} í¬í•¨"
    except Exception as e:
        print(f"   âš ï¸ Gemini API ì˜¤ë¥˜: {str(e)}")
        return f"[ë¶„ì„ ë¶ˆê°€] {', '.join(matched_keywords)} í¬í•¨"


# 3-1. Daily Bridge ìƒì„± í•¨ìˆ˜ (ìƒˆë¡œìš´ ê¸°ëŠ¥!)
def create_daily_bridge(news_data_list):
    """
    ë§¤ì¼ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ì¤‘ TOP 3ì„ ì •ì œí•˜ì—¬ Daily_Bridge.md ìƒì„±
    ì´ íŒŒì¼ì´ VS Code â†” Antigravity ì—°ê²°ì 
    """
    if not news_data_list:
        print("   âš ï¸ ë¶„ì„í•  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    timestamp = datetime.now().strftime("%Yë…„ %mì›” %dì¼ %H:%M:%S")
    
    # TOP 3 ì„ ì •ì„ ìœ„í•´ Gemini í˜¸ì¶œ
    failed = False
    try:
        all_news = "\n\n".join([f"- {item['text']}" for item in news_data_list])
        
        prompt = f"""ë‹¹ì‹ ì€ Wave Tree í”„ë¡œì íŠ¸ì˜ ë‰´ìŠ¤ íŽ¸ì§‘ìžìž…ë‹ˆë‹¤.
ë‹¤ìŒ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ë“¤ ì¤‘ì—ì„œ ì§„ì•ˆ Farmerstreeì˜ ê· ì‚¬ì²´ ì—°êµ¬ì™€ ì„œë²„ ì¸í”„ë¼ì— **ì§ì ‘ì ì¸ ì˜í–¥**ì„ ì¤„ ë§Œí•œ 
**í•µì‹¬ ì •ë³´ TOP 3ê°œ**ë¥¼ ì„ ì •í•´ì¤˜.

ì„ ì • ê¸°ì¤€:
1. ê· ì‚¬ì²´/ë°°ì–‘ìœ¡ ê¸°ìˆ  ë°œì „ë„
2. ë¹„ìš© íš¨ìœ¨ì„± ê°œì„  ì—¬ë¶€
3. ì„œë²„ ì¸í”„ë¼/AI ê¸°ìˆ ê³¼ì˜ ì—°ê³„ì„±

ë‰´ìŠ¤ ëª©ë¡:
{all_news}

ì‘ë‹µ í˜•ì‹ (ë§ˆí¬ë‹¤ìš´):
## ë ˆì´ë” ê°ì§€ ê²°ê³¼ (TOP 3)

### 1ï¸âƒ£ [ì œëª©]
- ì›ë¬¸: [ì›ë³¸ ë‰´ìŠ¤ í•œì¤„]
- ì˜í–¥ë„: [ì ìˆ˜/10]
- ì‹¤í–‰ ì¸ì‚¬ì´íŠ¸: [êµ¬ì²´ì  ì•¡ì…˜]

### 2ï¸âƒ£ [ì œëª©]
- ì›ë¬¸: [ì›ë³¸ ë‰´ìŠ¤ í•œì¤„]
- ì˜í–¥ë„: [ì ìˆ˜/10]
- ì‹¤í–‰ ì¸ì‚¬ì´íŠ¸: [êµ¬ì²´ì  ì•¡ì…˜]

### 3ï¸âƒ£ [ì œëª©]
- ì›ë¬¸: [ì›ë³¸ ë‰´ìŠ¤ í•œì¤„]
- ì˜í–¥ë„: [ì ìˆ˜/10]
- ì‹¤í–‰ ì¸ì‚¬ì´íŠ¸: [êµ¬ì²´ì  ì•¡ì…˜]"""
        
        bridge_content = generate_text_with_retry(prompt)
        if not bridge_content:
            failed = True
    except Exception as e:
        print(f"   âš ï¸ Daily Bridge ìƒì„± ì˜¤ë¥˜: {str(e)}")
        failed = True
        bridge_content = ""

    if failed:
        print("   âš ï¸ Daily Bridge ìƒì„± ì‹¤íŒ¨ë¡œ ê¸°ì¡´ íŒŒì¼ì„ ìœ ì§€í•©ë‹ˆë‹¤.")
        return None
    
    # Daily_Bridge.md ìƒì„±
    full_content = f"""# ðŸ“¡ Daily Bridge - {timestamp}

**ì´ íŒŒì¼ì€ VS Codeì™€ Antigravityë¥¼ ì—°ê²°í•˜ëŠ” ì¸ì‚¬ì´íŠ¸ ë¸Œë¦¿ì§€ìž…ë‹ˆë‹¤.**

{bridge_content}

---

## ë‹¤ìŒ ë‹¨ê³„
ì´ ë‚´ìš©ì„ Antigravityì— ë³µì‚¬í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì´ ì§ˆë¬¸í•˜ì„¸ìš”:
> "ì˜¤ëŠ˜ì˜ ë ˆì´ë” ê°ì§€ ê²°ê³¼ì•¼. 
> ì´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í˜„ìž¬ Wave Tree Project Dashboardì—ì„œ 
> ìˆ˜ì •í•˜ê±°ë‚˜ ìƒˆë¡œ ì¶”ê°€í•´ì•¼ í•  To-Do ì¹´ë“œ 3ê°œë¥¼ ë½‘ì•„ì¤˜."

ìƒì„± ì‹œê°: {timestamp}
"""
    
    # íŒŒì¼ ì €ìž¥
    try:
        with open(DAILY_BRIDGE_PATH, "w", encoding="utf-8") as f:
            f.write(full_content)
        print(f"   âœ… Daily_Bridge.md ìƒì„± ì™„ë£Œ: {DAILY_BRIDGE_PATH}")
        return DAILY_BRIDGE_PATH
    except Exception as e:
        print(f"   âš ï¸ Daily_Bridge.md ì €ìž¥ ì‹¤íŒ¨: {str(e)}")
        return None


def append_daily_bridge_to_news_json(bridge_path, category="global_biz"):
    if not bridge_path or not os.path.exists(bridge_path):
        print("   âš ï¸ Daily Bridge íŒŒì¼ì´ ì—†ì–´ news.json ì¶”ê°€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return False

    news_json_path = os.path.join(BASE_DIR, "data", "normalized", "news.json")

    try:
        with open(bridge_path, "r", encoding="utf-8") as f:
            content = f.read()
    except Exception as e:
        print(f"   âš ï¸ Daily Bridge ì½ê¸° ì‹¤íŒ¨: {str(e)}")
        return False

    date_match = re.search(r"(\d{4})ë…„\s*(\d{2})ì›”\s*(\d{2})ì¼", content)
    if date_match:
        date_str = f"{date_match.group(1)}-{date_match.group(2)}-{date_match.group(3)}"
    else:
        date_str = datetime.now().strftime("%Y-%m-%d")

    bridge_id = f"daily_bridge_{date_str}"
    title = f"Daily Bridge {date_str}"

    bullets = []
    for line in content.splitlines():
        text = line.strip()
        if text.startswith("*"):
            bullets.append(text.lstrip("* ").strip())
        if len(bullets) >= 3:
            break

    summary = " ".join(bullets).strip()
    if not summary:
        summary = content.replace("\n", " ")
    summary = " ".join(summary.split()).strip()
    summary = summary[:180]

    try:
        if os.path.exists(news_json_path):
            with open(news_json_path, "r", encoding="utf-8") as f:
                data = json.load(f)
        else:
            data = {"generated_at": datetime.now().isoformat(), "items": []}

        items = data.get("items", [])
        if any(str(item.get("id")) == bridge_id for item in items):
            print("   â„¹ï¸ Daily Bridgeê°€ ì´ë¯¸ news.jsonì— ì¡´ìž¬í•©ë‹ˆë‹¤.")
            return False

        items.insert(0, {
            "id": bridge_id,
            "category": category,
            "title": title,
            "source": "Daily_Bridge",
            "url": None,
            "published_at": datetime.now().isoformat(),
            "summary": summary,
            "highlights": [],
            "tags": ["daily_bridge"],
            "score": 0.95
        })

        data["generated_at"] = datetime.now().isoformat()
        data["items"] = items

        os.makedirs(os.path.dirname(news_json_path), exist_ok=True)
        with open(news_json_path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"   âœ… Daily Bridgeê°€ news.jsonì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤: {news_json_path}")
        return True
    except Exception as e:
        print(f"   âš ï¸ news.json ì¶”ê°€ ì‹¤íŒ¨: {str(e)}")
        return False


# 4. ê²°ê³¼ ì €ìž¥ (Markdown)
def save_to_radar(news_text, matched_keywords, analysis=None):
    """Project_Radar.mdì— ê²°ê³¼ ì €ìž¥ ë° Antigravityë¡œ ìžë™ ë™ê¸°í™”"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    radar_file = "Project_Radar.md"
    
    # íŒŒì¼ì´ ì—†ìœ¼ë©´ í—¤ë” ìƒì„±
    if not os.path.exists(radar_file):
        with open(radar_file, "w", encoding="utf-8") as f:
            f.write("# Project Radar - ë‰´ìŠ¤ ê°ì§€ ë¡œê·¸\n\n")
    
    with open(radar_file, "a", encoding="utf-8") as f:
        f.write(f"## [{timestamp}] ì‹ ê·œ ê°ì§€\n")
        f.write(f"**ë‰´ìŠ¤**: {news_text[:100]}...\n\n")
        f.write(f"**ê°ì§€ í‚¤ì›Œë“œ**: {', '.join(matched_keywords)}\n\n")
        if analysis:
            f.write(f"**ë¶„ì„**: {analysis}\n")
        f.write("\n---\n\n")
    
    # Antigravityë¡œ ìžë™ ë™ê¸°í™”
    try:
        shutil.copy2(radar_file, ANTIGRAVITY_PATH)
        print(f"   ðŸ”„ Antigravity ë™ê¸°í™” ì™„ë£Œ: {ANTIGRAVITY_PATH}")
    except Exception as e:
        print(f"   âš ï¸ Antigravity ë™ê¸°í™” ì‹¤íŒ¨: {str(e)}")


# 5. JSONìœ¼ë¡œë„ ì €ìž¥ (API ì—°ë™ ìš©)
def save_to_json(news_data):
    """ê°ì§€ëœ ë‰´ìŠ¤ë¥¼ JSONìœ¼ë¡œ ì €ìž¥"""
    json_file = "detected_news.json"
    
    try:
        with open(json_file, "r", encoding="utf-8") as f:
            data = json.load(f)
    except FileNotFoundError:
        data = []
    
    data.append({
        "timestamp": datetime.now().isoformat(),
        "news": news_data["text"],
        "keywords": news_data["keywords"],
        "analysis": news_data.get("analysis", "")
    })
    
    with open(json_file, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


# Dashboard ì—…ë°ì´íŠ¸ í•¨ìˆ˜
def update_dashboard(news_data_list):
    """
    dashboard_data.jsonì˜ intelligence ì„¹ì…˜ì„ ìµœì‹  ë‰´ìŠ¤ë¡œ ì—…ë°ì´íŠ¸
    """
    dashboard_env = os.getenv("DASHBOARD_DATA_PATH", "").strip()
    if dashboard_env:
        DASHBOARD_PATH = dashboard_env
    else:
        workspace_root = os.path.abspath(os.path.join(BASE_DIR, ".."))
        DASHBOARD_PATH = os.path.join(workspace_root, "woonmok.github.io", "dashboard_data.json")
    
    if not news_data_list:
        print("   âš ï¸ ì—…ë°ì´íŠ¸í•  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    try:
        # ê¸°ì¡´ dashboard_data.json ë¡œë“œ
        if os.path.exists(DASHBOARD_PATH):
            with open(DASHBOARD_PATH, 'r', encoding='utf-8') as f:
                dashboard_data = json.load(f)
        else:
            dashboard_data = {
                "todo_list": [],
                "system_status": "NORMAL",
                "intelligence": []
            }
        
        # ìƒìœ„ 3ê°œ ë‰´ìŠ¤ ì¶”ì¶œ
        top_news = []
        for item in news_data_list[:3]:
            title = item.get('text', '')[:100]  # ì œëª© ì¶”ì¶œ
            analysis = item.get('analysis', '')
            
            # ê°„ë‹¨í•œ ìš”ì•½ ì¶”ì¶œ (ì²« ë¬¸ìž¥)
            summary = analysis.split('.')[0] if analysis else "ë¶„ì„ ì¤‘"
            
            # ì¹´í…Œê³ ë¦¬ íŒë‹¨
            keywords = item.get('keywords', [])
            if any(kw in ['listeria', 'ë¦¬ìŠ¤í…Œë¦¬ì•„'] for kw in keywords):
                tag = "ê¸´ê¸‰"
                score = "0.95"
            elif any(kw in ['ë°°ì–‘ìœ¡', 'cultured meat', 'ê· ì‚¬ì²´'] for kw in keywords):
                tag = "ì¤‘ìš”"
                score = "0.85"
            else:
                tag = "ì •ë³´"
                score = "0.75"
            
            top_news.append({
                "title": title,
                "summary": summary[:150],
                "tag": tag,
                "score": score
            })
        
        # intelligence ì„¹ì…˜ ì—…ë°ì´íŠ¸
        dashboard_data["intelligence"] = top_news
        dashboard_data["last_updated"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # ì €ìž¥
        with open(DASHBOARD_PATH, 'w', encoding='utf-8') as f:
            json.dump(dashboard_data, f, ensure_ascii=False, indent=2)
        
        print(f"   âœ… Dashboard ì—…ë°ì´íŠ¸ ì™„ë£Œ: {len(top_news)}ê°œ ë‰´ìŠ¤")
        
    except Exception as e:
        print(f"   âš ï¸ Dashboard ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {str(e)}")


# 6. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def process_news(use_gemini=True):
    """ë‰´ìŠ¤ í•„í„°ë§ ë° ë¶„ì„ ë©”ì¸ í•¨ìˆ˜ + Daily_Bridge.md ìƒì„±"""
    news_list = fetch_news()
    processed_count = 0
    skipped_count = 0
    processed_news_data = []
    
    print("=" * 60)
    print("ðŸ›°ï¸ ì™¸ë¶€ ì •ë³´ ê°ì§€ ì‹œìŠ¤í…œ ê°€ë™ ì¤‘...")
    print("=" * 60)
    print(f"ðŸ“‹ ê°ì§€ í‚¤ì›Œë“œ ({len(KEYWORDS)}ê°œ): {', '.join(KEYWORDS[:5])}...")
    print(f"ðŸš« ì œì™¸ í‚¤ì›Œë“œ ({len(EXCLUDE_KEYWORDS)}ê°œ): {', '.join(EXCLUDE_KEYWORDS)}\n")
    
    for idx, news in enumerate(news_list, 1):
        print(f"\n[{idx}/{len(news_list)}] ì²˜ë¦¬ ì¤‘...")
        print(f"   ðŸ“ ë‰´ìŠ¤: {news[:60]}...")
        
        # í‚¤ì›Œë“œ í•„í„°ë§
        is_relevant, result = filter_by_keywords(news)
        
        if not is_relevant:
            print(f"   âœ— ê±´ë„ˆëœ€: {result}")
            skipped_count += 1
            continue
        
        matched_keywords = result
        print(f"   âœ“ í•„í„° í†µê³¼!")
        print(f"   ðŸŽ¯ ê°ì§€ëœ í‚¤ì›Œë“œ: {', '.join(matched_keywords)}")
        
        # Gemini ë¶„ì„ (ê¸°ë³¸ í™œì„±í™”)
        analysis = None
        if use_gemini:
            try:
                print(f"   ðŸ”„ Gemini ë¶„ì„ ì§„í–‰ ì¤‘...")
                analysis = analyze_importance(news, matched_keywords)
                print(f"   âœ… ë¶„ì„ ì™„ë£Œ")
            except Exception as e:
                print(f"   âš ï¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        
        # Markdown ì €ìž¥
        try:
            save_to_radar(news, matched_keywords, analysis)
            print(f"   ðŸ’¾ Markdown ì €ìž¥ ì™„ë£Œ")
        except Exception as e:
            print(f"   âš ï¸ ì €ìž¥ ì˜¤ë¥˜: {str(e)}")
        
        # JSON ì €ìž¥
        try:
            save_to_json({
                "text": news,
                "keywords": matched_keywords,
                "analysis": analysis or ""
            })
            print(f"   ðŸ’¾ JSON ì €ìž¥ ì™„ë£Œ")
        except Exception as e:
            print(f"   âš ï¸ JSON ì €ìž¥ ì˜¤ë¥˜: {str(e)}")
        
        # Daily Bridge ìƒì„±ìš© ë°ì´í„° ìˆ˜ì§‘
        processed_news_data.append({
            "text": news,
            "keywords": matched_keywords,
            "analysis": analysis
        })
        
        processed_count += 1
    
    # Daily_Bridge.md ìƒì„± (í•µì‹¬!)
    print("\n" + "=" * 60)
    print("ðŸŒ‰ Daily Bridge ìƒì„± ì¤‘...")
    print("=" * 60)
    bridge_path = create_daily_bridge(processed_news_data)

    # Daily_Bridge.md -> news.json append
    if bridge_path:
        append_daily_bridge_to_news_json(bridge_path, category="global_biz")
    
    # Dashboard ì—…ë°ì´íŠ¸
    print("\n" + "=" * 60)
    print("ðŸ“Š Dashboard ì—…ë°ì´íŠ¸ ì¤‘...")
    print("=" * 60)
    update_dashboard(processed_news_data)
    
    # Intelligence Hub ì—…ë°ì´íŠ¸ (index.html)
    print("\n" + "=" * 60)
    print("ðŸŒ Intelligence Hub ì—…ë°ì´íŠ¸ ì¤‘...")
    print("=" * 60)
    try:
        from sync_top_news import sync_to_html
        sync_to_html()
        print("   âœ… Intelligence Hub ì—…ë°ì´íŠ¸ ì™„ë£Œ")
    except Exception as e:
        print(f"   âš ï¸ Intelligence Hub ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {str(e)}")
    
    print("\n" + "=" * 60)
    print(f"âœ… ë¶„ì„ ì™„ë£Œ. ëª¨ë“  íŒŒì¼ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"   âœ“ ì €ìž¥ë¨: {processed_count}ê°œ")
    print(f"   âœ— ê±´ë„ˆëœ€: {skipped_count}ê°œ")
    print(f"   ðŸ“ ìƒì„± íŒŒì¼:")
    print(f"      - Project_Radar.md (Antigravity ë™ê¸°í™”)")
    print(f"      - detected_news.json (API ì—°ë™)")
    print(f"      - Daily_Bridge.md â­ (VS Code â†” Antigravity ë¸Œë¦¿ì§€)")
    print(f"      - dashboard_data.json â­ (ëŒ€ì‹œë³´ë“œ ë™ê¸°í™”)")
    print(f"      - index.html Intelligence Hub â­ (ì›¹ì‚¬ì´íŠ¸ ë™ê¸°í™”)")
    print("=" * 60)


# ì‹¤í–‰
if __name__ == "__main__":
    # use_gemini=Trueë¡œ ì„¤ì •í•˜ë©´ Gemini API ì‚¬ìš© (API í‚¤ í•„ìš”)
    # ìžë™ ìŠ¤ì¼€ì¤„ëŸ¬(Daily Bridge)ì—ì„œ í•­ìƒ Gemini=Trueë¡œ ì‹¤í–‰ë¨
    import sys
    use_gemini = True
    if len(sys.argv) > 1 and sys.argv[1] == "--no-gemini":
        use_gemini = False
    
    process_news(use_gemini=use_gemini)

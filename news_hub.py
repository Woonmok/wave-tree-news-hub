#!/usr/bin/env python3
# news_hub.py (Gemini API ê¸°ë°˜ ë‰´ìŠ¤ ë¶„ì„)
import os
import google.generativeai as genai
from datetime import datetime
import json

# Gemini API ì„¤ì •
os.environ["GOOGLE_API_KEY"] = os.getenv("GOOGLE_API_KEY", "YOUR_GEMINI_API_KEY")
genai.configure(api_key=os.environ["GOOGLE_API_KEY"])
model = genai.GenerativeModel('gemini-1.5-pro')

# ===== ì„¤ì • =====
KEYWORDS = [
    "ê· ì‚¬ì²´", "mycelium", "ë°°ì–‘ìœ¡", "cultured meat",
    "ì§„ì•ˆ", "POM", "Bio-R&D", "ë°”ì´ì˜¤",
    "cell-based", "fermentation", "ë°°ì–‘",
    "listeria", "ë¦¬ìŠ¤í…Œë¦¬ì•„", "ê³ ê¸‰ ì˜¤ë””ì˜¤", "í•˜ì´ì—”ë“œ",
    "ai", "computer", "gpu", "blackwell"
]

EXCLUDE_KEYWORDS = [
    "ê´‘ê³ ", "ìŠ¤í°ì„œ", "sponsored", "promo", "affiliate"
]

# 1. í‚¤ì›Œë“œ í•„í„°ë§ í•¨ìˆ˜
def filter_by_keywords(news_text, keywords=KEYWORDS, exclude=EXCLUDE_KEYWORDS):
    """íŠ¹ì • í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë‰´ìŠ¤ë§Œ ì„ íƒ"""
    text_lower = news_text.lower()
    
    # ì œì™¸ í‚¤ì›Œë“œ í™•ì¸
    for exclude_kw in exclude:
        if exclude_kw.lower() in text_lower:
            return False, "ì œì™¸ í‚¤ì›Œë“œ í¬í•¨"
    
    # í¬í•¨ í‚¤ì›Œë“œ í™•ì¸
    matched_keywords = [kw for kw in keywords if kw.lower() in text_lower]
    if matched_keywords:
        return True, matched_keywords
    
    return False, "ê´€ë ¨ í‚¤ì›Œë“œ ì—†ìŒ"


# 2. ì •ë³´ ìˆ˜ì§‘ (RSS/API)
def fetch_news():
    """ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ (2026ë…„ ì‹œì¥ íŠ¸ë Œë“œ ì‹œë®¬ë ˆì´ì…˜)"""
    # ì‹¤ì œ ìš´ì˜ ì‹œ: NewsAPIë‚˜ RSS í”¼ë“œë¥¼ ì—°ë™í•©ë‹ˆë‹¤.
    sample_news = [
        "ë¯¸êµ­ ë‚´ ë°°ì–‘ìœ¡ ì‹œì¥, ê³ ë¹„ìš© ë¬¸ì œë¡œ ì„¸í¬ ë°°ì–‘ ë°©ì‹ì—ì„œ ê· ì‚¬ì²´(Mycelium) ê¸°ë°˜ ë°œíš¨ ë°©ì‹ìœ¼ë¡œ ê¸‰ê²©í•œ ì´ë™ ì¤‘",
        "Better Meat Co ë° Prime Roots, ì‚°ì—…ìš© ì—°ì† ë°œíš¨ ì‹œìŠ¤í…œ ë„ì…ìœ¼ë¡œ ìƒì‚° ë‹¨ê°€ 30% ì ˆê° ì„±ê³µ",
        "2026ë…„ í‘¸ë“œí…Œí¬ íŠ¸ë Œë“œ: 'Precision Fermentation'ê³¼ ë²„ì„¯ ê· ì‚¬ì²´ë¥¼ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ë‹¨ë°±ì§ˆ ë¶€ìƒ",
        "FDA ë¦¬ìŠ¤í…Œë¦¬ì•„ ê¸´ê¸‰ ì•Œë¦¼ ë°œí‘œ - ëƒ‰ì¥ ì‹í’ˆ ê´€ë ¨",
        "ê³ ê¸‰ ì˜¤ë””ì˜¤ ê¸°ìˆ  ìµœì‹  ë™í–¥ - DSD í¬ë§· ì£¼ë¥˜í™”",
        "NVIDIA Blackwell GPU, AI ì¸í”„ë¼ í˜ì‹  ì£¼ë„",
        "ìŠ¤íƒ€íŠ¸ì—… ê´‘ê³ : ìƒˆ ì œí’ˆ ì¶œì‹œ ìŠ¤í°ì„œë¨ (ì œì™¸ ëŒ€ìƒ)",
    ]
    return sample_news


# 3. Geminië¥¼ í†µí•œ ì „ëµì  í•„í„°ë§ (ëˆˆì˜ ì—­í• )
def analyze_importance(news_text, matched_keywords):
    """Geminië¥¼ ì‚¬ìš©í•œ ë‰´ìŠ¤ ì¤‘ìš”ë„ ë¶„ì„"""
    try:
        keywords_str = ", ".join(matched_keywords)
        prompt = f"""ë‹¹ì‹ ì€ 'ì§„ì•ˆ Farmerstree' í”„ë¡œì íŠ¸ì˜ ì „ëµ AIì…ë‹ˆë‹¤.
ë‹¤ìŒ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”:
1. í”„ë¡œì íŠ¸(ê· ì‚¬ì²´ ë°°ì–‘ìœ¡, ê³ ê¸‰ ì˜¤ë””ì˜¤, AI ì¸í”„ë¼)ì™€ì˜ ê´€ë ¨ì„± ì ìˆ˜ (1-10)
2. ì „ëµì  í‰ê°€ (2-3ì¤„)
3. ì•¡ì…˜ ì•„ì´í…œ (ìˆìœ¼ë©´)

ê°ì§€ëœ í‚¤ì›Œë“œ: {keywords_str}

ë‰´ìŠ¤: {news_text}

í˜•ì‹:
[ì ìˆ˜/10] | [ì œëª© í•œì¤„] 
ë¶„ì„: [ë‚´ìš©]
ì•¡ì…˜: [í•„ìš”ì‹œ]"""
        
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        print(f"   âš ï¸ Gemini API ì˜¤ë¥˜: {str(e)}")
        return f"[ë¶„ì„ ë¶ˆê°€] {', '.join(matched_keywords)} í¬í•¨"


# 4. ê²°ê³¼ ì €ì¥ (Markdown)
def save_to_radar(news_text, matched_keywords, analysis=None):
    """Project_Radar.mdì— ê²°ê³¼ ì €ì¥"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    radar_file = "Project_Radar.md"
    
    # íŒŒì¼ì´ ì—†ìœ¼ë©´ í—¤ë” ìƒì„±
    if not os.path.exists(radar_file):
        with open(radar_file, "w", encoding="utf-8") as f:
            f.write("# Project Radar - ë‰´ìŠ¤ ê°ì§€ ë¡œê·¸\n\n")
    
    with open(radar_file, "a", encoding="utf-8") as f:
        f.write(f"## [{timestamp}] ì‹ ê·œ ê°ì§€\n")
        f.write(f"**ë‰´ìŠ¤**: {news_text[:100]}...\n\n")
        f.write(f"**ê°ì§€ í‚¤ì›Œë“œ**: {', '.join(matched_keywords)}\n\n")
        if analysis:
            f.write(f"**ë¶„ì„**: {analysis}\n")
        f.write("\n---\n\n")


# 5. JSONìœ¼ë¡œë„ ì €ì¥ (API ì—°ë™ ìš©)
def save_to_json(news_data):
    """ê°ì§€ëœ ë‰´ìŠ¤ë¥¼ JSONìœ¼ë¡œ ì €ì¥"""
    json_file = "detected_news.json"
    
    try:
        with open(json_file, "r", encoding="utf-8") as f:
            data = json.load(f)
    except FileNotFoundError:
        data = []
    
    data.append({
        "timestamp": datetime.now().isoformat(),
        "news": news_data["text"],
        "keywords": news_data["keywords"],
        "analysis": news_data.get("analysis", "")
    })
    
    with open(json_file, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


# 6. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def process_news(use_gemini=True):
    """ë‰´ìŠ¤ í•„í„°ë§ ë° ë¶„ì„ ë©”ì¸ í•¨ìˆ˜"""
    news_list = fetch_news()
    processed_count = 0
    skipped_count = 0
    
    print("=" * 60)
    print("ğŸ›°ï¸ ì™¸ë¶€ ì •ë³´ ê°ì§€ ì‹œìŠ¤í…œ ê°€ë™ ì¤‘...")
    print("=" * 60)
    print(f"ğŸ“‹ ê°ì§€ í‚¤ì›Œë“œ ({len(KEYWORDS)}ê°œ): {', '.join(KEYWORDS[:5])}...")
    print(f"ğŸš« ì œì™¸ í‚¤ì›Œë“œ ({len(EXCLUDE_KEYWORDS)}ê°œ): {', '.join(EXCLUDE_KEYWORDS)}\n")
    
    for idx, news in enumerate(news_list, 1):
        print(f"\n[{idx}/{len(news_list)}] ì²˜ë¦¬ ì¤‘...")
        print(f"   ğŸ“ ë‰´ìŠ¤: {news[:60]}...")
        
        # í‚¤ì›Œë“œ í•„í„°ë§
        is_relevant, result = filter_by_keywords(news)
        
        if not is_relevant:
            print(f"   âœ— ê±´ë„ˆëœ€: {result}")
            skipped_count += 1
            continue
        
        matched_keywords = result
        print(f"   âœ“ í•„í„° í†µê³¼!")
        print(f"   ğŸ¯ ê°ì§€ëœ í‚¤ì›Œë“œ: {', '.join(matched_keywords)}")
        
        # Gemini ë¶„ì„ (ê¸°ë³¸ í™œì„±í™”)
        analysis = None
        if use_gemini:
            try:
                print(f"   ğŸ”„ Gemini ë¶„ì„ ì§„í–‰ ì¤‘...")
                analysis = analyze_importance(news, matched_keywords)
                print(f"   âœ… ë¶„ì„ ì™„ë£Œ")
            except Exception as e:
                print(f"   âš ï¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        
        # Markdown ì €ì¥
        try:
            save_to_radar(news, matched_keywords, analysis)
            print(f"   ğŸ’¾ Markdown ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            print(f"   âš ï¸ ì €ì¥ ì˜¤ë¥˜: {str(e)}")
        
        # JSON ì €ì¥
        try:
            save_to_json({
                "text": news,
                "keywords": matched_keywords,
                "analysis": analysis or ""
            })
            print(f"   ğŸ’¾ JSON ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            print(f"   âš ï¸ JSON ì €ì¥ ì˜¤ë¥˜: {str(e)}")
        
        processed_count += 1
    
    print("\n" + "=" * 60)
    print(f"âœ… ë¶„ì„ ì™„ë£Œ. Project_Radar.mdê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"   âœ“ ì €ì¥ë¨: {processed_count}ê°œ")
    print(f"   âœ— ê±´ë„ˆëœ€: {skipped_count}ê°œ")
    print(f"   ğŸ“ ìƒì„± íŒŒì¼: Project_Radar.md, detected_news.json")
    print("=" * 60)


# ì‹¤í–‰
if __name__ == "__main__":
    # use_gemini=Trueë¡œ ì„¤ì •í•˜ë©´ Gemini API ì‚¬ìš© (API í‚¤ í•„ìš”)
    process_news(use_gemini=False)
